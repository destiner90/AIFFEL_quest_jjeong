# 5장 토큰화 / 6장 임베딩

## 5장 토큰화
### 개요
#### 자연어와 자연어 처리
- 자연어(National Language) : 자연 언어라고 부르며, 사람들에 의해 자연스럽게 만들어진 언어를 의미함
- 자연어 처리(Natural Language Processing, NPL) : 컴퓨터가 인간의 언어를 이해하고 해석 및 생성하기 위한 기술을 의미함

#### 자연어 처리(NPL)의 목적
- 컴퓨터가 인간과 유사한 방식으로 언어를 이해하고 처리하는 것을 목표로 함
- 모델 개발을 위해 해결해야할 문제
  - 모호성(Ambiguity) : 맥락에 따라 다양한 의미를 가질 수 있는 모호성 해결
  - 가변성(Variability) : 사투리, 강세, 신조어 등에 의한 가변성을 처리할 수 있어야함
  - 구조(structure) : 문장의 구조와 문법적 요소를 이해하여 추론, 분석할 수 있어야함
- 말뭉치(Corpus)를 일정한 단위인 토큰(Token)으로 나눠야 함
  - 말뭉치? 자연어 모델을 훈련하고 평가하는 데 사용되는 대규모 자연어를 뜻함

#### 토큰?
- 개별 단어나 문장 부호와 같은 텍스트를 의미하며 말뭉치보다 더 작은 단위
- 텍스트의 개별 단어, 구두점 또는 기타 의미 단위일 수 있음
- 토큰으로 나누는 목적은 컴퓨터가 자연어를 이해할 수 있게 나누는 과정임
- 토큰으로 나누는 과정을 토큰화(Tokenization)라고 함
- 토큰화는 컴퓨터가 텍스트를 보다 효율적으로 분석하고 처리할 수 있도록 하는 중요한 단계

#### 토크나이저(Tokenizer)
- 텍스트 문자열을 토큰으로 나누는 알고리즘 또는 소프트웨어를 의미함
- 일반적으로 토큰을 나누는 여러 기준
  - 공백 분할 : 텍스트를 공백 단위로 분리해 개별 단어로 토큰화
  - 정규표현식 적용 : 정규 표현식으로 특정 패턴을 식별해 텍스트 분할
  - 어휘 사전(Vocabulary) : 사전에 정의된 단어 집합을 토큰으로 사용
  - 머신러닝 활용 : 데이터세트를 기반으로 토큰화하는 방법을 학습한 머신러닝을 적용

#### OOV(Out of Vocab)
- 어휘 사전에 없는 단어나 토큰이 존재하는 경우

### 단어 및 글자 토큰화
#### 단어 토큰화
- 자연어 처리 분야에서 핵심적인 전처리 작업 중 하나로 텍스트 데이터를 의미 있는 단위인 단어로 분리하는 작업
- 띄어쓰기, 문장 부호, 대소문자 등의 특정 구분자를 활용해 토큰화 수행됨

#### 글자 토큰화
- 띄어쓰기뿐만이 아니라 글자 단위로 문장을 나누는 방식
- 비교적 작은 단어 사전을 구축할 수 있어서 컴퓨팅 자원을 아낄수 있음
- 또한, 전체 말뭉치를 학습할 때 각 단어를 더 자주 학습할 수 있다는 장점이 있음
- 단점은 구조적 의미 파악이 어려움

### 형태소 토큰화
- 텍스트를 형태소 단위로 나누는 토큰화 방식
- 언어의 문법 구조를 고려해 단어를 분리하고 이를 의미 있는 단위로 분류하는 작업
- 특히 한국어와 같이 교착어(Agglutinative Language)인 언어에서 중요하게 수행됨

#### 형태소 종류
- 자립 형태소(Free Morpheme) : 명사, 동사, 형용사와 같이 스스로 의미를 가지고 있음
- 의존 형태소(Bound Morpheme) : 조사, 어미, 접두사, 접미사 등 스스로 의미를 갖지 못하고 다른 형태소와 조합되어 사용됨

#### 형태소 어휘 사전
- 각 단어의 형태소 정보를 포함하는 사전을 의미함
- 일반적으로 각 형태소가 어떤 품사에 속하지는지와 해당 품사의 뜻 등의 정보도 함께 제공됨

#### 품사 태깅(POS Tagging)
- 텍스트 데이터의 형태소를 분석하여 각 형태소에 해당하는 품사(Part of Speech, POS)를 태깅하는 작업을 의미함
- 자연어 처리 분야에서 문맥을 고려할 수 있도록 함

### 하위 단어 토큰화
- 형태소 분석은 띄어쓰기나 맞춤법이 잘 지켜지지 않는 경우, 신조어나 외래어, 전문용어, 축약어 등에 대해 완벽히 대응하기 어려움
- 즉, 형태소 분석기는 모르는 단어를 적절한 단위로 나누는 것에 취약하며, 잠재적으로 어휘 사전의 크기를 크게 만들고 OOV에 대응하기 어렵게 만듦
- 이를 해결하귀 위한 방법으로, **하위 단어 토큰화(Subword Tokenization)가 있음
- 하나의 단어가 빈번하게 사용되는 하위 단어(Subword)의 조합으로 나누어 토큰화 하는 방법
- 예를 들어, 'Reinforcement'라는 단어에 하위 단어 토큰화를 적용하여, 'Rein', 'force', 'ment'등으로 나눠 처리하는 방식임
- 하위 단어 토큰화를 적용하면, 단어의 길이를 줄일 수 있어서 처리 속도가 빨라지고, OOV문제, 신조어, 은어, 고유어 등으로 인한 문제를 완화할 수 있음


  

##### 
